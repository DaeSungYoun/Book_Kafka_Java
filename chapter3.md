# 3. 카프카 기본 개념 설명
## 3.1 카프카 브로커, 클러스터, 주키퍼
* 카프카 브로커는 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체이자 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션이다
* ## 데이터 저장, 전송
    * 카프카는 페이지 캐시를 사용하여 디스크 입출력 속도를 높임
    * 페이지 캐시란 OS에서 파일 입출력의 성능 향상을 위해 만들어 놓은 메모리 영역을 뜻한다.
    * 한번 읽은 파일의 내용은 메모리의 페이지 캐시 영역에 저장 시킨다.
    * 추후 동일한 파일의 접근이 일어나면 디스크에서 읽지 않고 메모리에서 직접 읽는 방식
    * 이러한 특징 떄문에 카프카 브로커를 실행하는데 힙 메모리 사이즈를 크게 설정할 필요가 없다
* ## 데이터 복제, 싱크
    * 데이터 복제(replication)는 카프카를 장애 허용 시스템으로 동작하도록 하는 원동력이다
    * 복제의 이유는 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함이다.
    * 카프카의 데이터 복제는 파티션 단위로 이루어진다.
    * 토픽을 생성할 때 파티션의 복제 개수도 같이 설정되는데 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션 값을 따라간다.
    * 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 `리더`, 나머지 복제 데이터를 가지고 있는 파티션을 `팔로워`라고 부른다.
    * 팔로워 파티션들은 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장하는데, 이 과정을 복제(replication)라고 부른다.
* ## 컨트롤러
    * 클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다.
    * 컨트롤러는 `다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배`한다.
    * 만약 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을 한다.
* ## 데이터 삭제
    * 카프카는 다른 메시징 플랫폼과 다르게 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다
    * 또한 컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없다.
    * 오직 브로커만이 데이터를 삭제할 수 있다. 데이터 삭제는 파일 단위로 이루어 지는데 이 단위를 `로그 세그먼트`라고 부른다.
    * 이 세그먼트에는 다수의 데이터가 들어 있기 때문에 일반적인 데이터베이스처럼 특정 데이터를 선별해서 삭제할 수 없다.
    * 세그먼트는 데이터가 쌓이는 동안 파일 시스템으로 열려있으며 카프카 브로커에 `log.segement.btyes` 또는 `log.segment.ms`옵션에 값이 설정되면 세그먼트 팡ㄹ이 닫힌다.
    * 세그먼트 파일이 닫히게 되는 기본값은 1GB용량에 도달했을 때인데 간격을 더 줄이고 싶다면 작은 용량으로 설정하면 된다.
    * 그러나 너무 작은 용량으로 설정하면 데이터들을 저장하는 동안 세그먼트 파일을 자주 여닫음으로써 부하가 발생할 수 있으므로 주의해야 한다.
    * 닫힌 세그먼트 파일은 `log.retention.bytes` 또는 `log.retention.ms` 옵션에 설정값이 넘으면 삭제된다.
    * 닫힌 세그먼트 파일을 체크하는 간격은 카프카 브로커의 옵션에 설정된 `log.retention.check.interval.ms`에 따른다.
* ## 컨슈머 오프셋 저장
    * 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.
    * 커밋한 오프셋은 `_consumer_offsets` 토픽에 저장
    * 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가서 처리한다
* ## 코디네이터(coordinator)
    * 클러스터의 다수 브로커 중 한 대는 코디네이터의 역할을 수행한다.
    * 코디네이터는 `컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할`을 한다
    * 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다.
    * 이렇게 파티션을 컨슈머로 재할당하는 과정을 `리밸런스`라고 부른다.
* ## 주키퍼
    * 주키퍼는 카프카의 메타데이터를 관리하는 데에 사용된다.
        ```bash
        bin/zookeeper-shell.sh my-kafka:2181
        ```
    > 주키퍼에서 다수의 카프카 클러스터를 사용하는 방법<br><br>
    주키퍼의 서로 다른 znode에 카프카 클러스터들을 설정하면 된다.<br>
    znode란 주키퍼에서 사용하는 데이터 저장 단위이다. 마치 파일 시스템처럼 znode 간에 계층 구조를 가진다.<br>
    1개의 znode에는 n개의 하위 znode가 존재하고 계속해서 tree 구조로 znode가 존재할 수 있다.<br>
    2개 이상의 카프카 클러스터를 구축할 때는 root znode(최상위 znode)가 아닌 한 단계 아래의 znode를 카프카 브로커 옵션으로 지정하도록 한다.<br>
    각기 다른 하위 znode로 설정된 서로 다른 카프카 클러스터는 각 클러스터의 데이터에 영향을 미치지 않고 정상 동작한다.
## 3.2 토픽과 파티션
* 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위이다.
* 토픽은 1개 이상의 파티션을 소유하고 있다. 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데 이 데이터를 `레코드`라고 부른다
* 파티션은 카프카의 병렬처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.
* 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃하는 것이다.
* 컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량이 증가하는 효과를 볼 수 있다.
* ## 토픽 이름 제약 조건
    * 빈 문자열 토픽 이름은 지원하지 않는다.
    * 토픽 이름은 마침표 하나(.) 또는 마침표 둘(..)로 생성될 수 없다.
    * 토픽 이름의 길이는 249자 미만으로 생성되어야 한다.
    * 토픽 이름은 영어 대소문자와 숫자 0부터 9 그리고 마침표(.), 언더바(_), 하이픈(-) 조합으로 새엇ㅇ할 수 있다. 이외의 문자열이 포함된 토픽 이름은 생성 불가하다.
    * 카프카 내부 로직 관리 목적으로 사용되는 2개 토픽(_consumer_offsets, _transaction_state)과 동일한 이름으로 생성 불가능 하다.
    * 카프카 내부적으로 사용하는 로직 때문에 토픽 이름에 마침표(.)와 언더바( _ )가 동시에 들어가면 안 된다. 생성은 할 수 있지만 사용 시 이슈가 발생할 수 있기 때문에 마침표(.)와 언더바( _ )가 들어간 토픽 이름을 사용하면 WARNING 메시지가 발생한다.
    * 이미 생성된 토픽 이름의 마침표(.)를 언더바(_ )로 바꾸거나 언더바(_ )를 마침표(.)로 바꾼 경우 신규 토픽 이름과 동일하다면 생성할 수 없다. 예를들어, to.pic 이름의 토픽이 생성되어 있다면 to_pic 이름의 토픽을 생성할 수 없다.
* ## 의미 있는 토픽 이름 작명 방법
    * 토픽 이름을 통해 어떤 개발환경에서 사용되는 것인지 판단 가능해야 하고 어떤 애플리케이션에서 어떤 데이터 타입으로 사용되는지 유추할 수 있어야 한다.
    * 휴먼에러로 인한 실수를 방지하기 위해 대문자와 소문자를 섞어서 쓰는 카멜케이스를 사용하기보다는 케밥케이스(kebab-case) 또는 스네이크 표기법(snake_case)과 같이 소문자를 쓰되 구분자로 특수문자를 조합하여 사용하면 좋다.
        > 토픽 작명의 템플릿과 예시<br><br>
        <환경>.<팀-명>.<애플리케이션-명>.<메시지-타입><br>
        예시) prd.marketing-team.sms-platform.json<br><br>
        <프로젝트-명>.<서비스-명>.<환경>.<이벤트-명><br>
        예시) commerce.payment.prd.notification<br><br>
        <환경>.<서비스-명>.<JIRA-번호>.<메시지-타입><br>
        예시) dev.email-sender.jira-1234.email-vo-custom<br><br>
        <카프카-클러스터-명>.<환경>.<서비스-명>.<메시지-타입><br>
        예시) aws-kafka.live.marketing-platform.json
## 3.3 레코드
* 레코드는 `타입스탬프`, `메시지 키`, `메시지 값`, `오프셋`, `헤더`로 구성되어 있다
* 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다.
* **브로커에 한번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.**
* 타임스탬프는 프로듀서에서 해당 레코드가 생성된 시점(createTime)의 유닉스 타입이 설정된다.
* 컨슈머는 레코드의 타임스탬프를 토대로 레코드가 언제 생성되었는지 알 수 있다.
* 다만, 프로듀서가 레코드를 생성할 때 임의의 타임스탬프 값을 설정할 수 있고, 토픽 설정에 따라 브로커에 적재된 시간으로 설정될 수 있다는 점을 유의해야 한다.
* 메시지 키는 메시지 값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용한다.
* 메시지 키를 사용하면 프로듀서가 토픽에 레코드를 전송할 때 메시지 키의 해시값을 토대로 파티션을 지정하게 된다. 
* 즉, 동일한 메시지 키라면 동일 파티션에 들어가는 것이다. 다만, 어느 파티션에 지정될지 알 수 없고 파티션 개수가 변경되면 메시지 키와 파티션 매칭이 달라지게 되므로 주의해야 한다.
* 만약 메시지 키를 사용하지 않는다면 프로듀서에서 레코드를 전송할 때 메시지 키를 선언하지 않으면 된다.
* 메시지 키를 선언하지 않으면 null로 설정된다.
* 메시지 키가 null로 설정된 레코드는 프로듀서 기본 설정 파티셔너에 따라서 파티션에 분배되어 적재된다.
* 메시지 값에는 실질적으로 처리할 데이터가 들어있다.
* 메시지 키와 메시지 값은 직렬화되어 브로커로 전송되기 떄문에 컨슈머가 이용할 때는 직렬화한 형태와 동일한 형태로 역직렬화를 수행해야 한다.
* 직렬화, 역직렬화할 때는 반드시 동일한 형태로 처리해야 한다. 
* 만약 프로듀서가 StringSerializer로 직렬화한 메시지 값을 컨슈머가 IntegerDeserializer로 역직렬화하면 정상적인 데이터를 얻을 수 없다.
* 레코드의 오프헷은 0 이상의 숫자로 이루어져 있다.
* 레코드의 오프셋은 직접 지정할 수 없고 브로커에 저장될 떄 이전에 전송된 레코드의 오프셋+1 값으로 생성된다.
* 오프셋은 카프카 컨슈머가 데이터를 가져갈 떄 사용된다.
* 오프셋을 사용하면 컨슈머 그룹으로 이루어진 카프카 컨슈머들이 파티션의 데이터를 어디까지 가져갔는지 명확히 지정할 수 있다.
* 헤더는 레코드의 추가적인 정보를 담는 메타데이터 저장소 용도로 사용한다.
* 헤더는 키/값 형태로 데이터를 추가하여 레코드의 속성(스키마 버전 등)을 저장하여 컨슈머에서 참조할 수 있다.
## 3.4 카프카 클라이언트
* 카프카 클러스터에 명령을 내려거나 데이터를 송수신하기 위해 카프카 클라이언트 라이브러리는 카프카 프로듀서, 컨슈머, 어드민 클라이언트를 제공하는 카프카 클라이언트를 사용하여 애플리케이션을 개발한다.
* 카프카 클라이언트는 라이브러리이기 떄문에 자체 라이플사이클을 가진 프레임워크나 애플리케이션 위에서 구현하고 실행해야 한다.
* ## 3.4.1 프로듀서 API
## 3.5 카프카 스트림즈
## 3.6 카프카 커넥트
## 3.7 카프카 미러메이커2
## 3.8 정리